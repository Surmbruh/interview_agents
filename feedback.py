from state import AgentState
from utils.report import generate_final_report, generate_development_roadmap
from utils.logger import LoggerUtils
from langchain_core.messages import AIMessage
from langchain_community.tools import DuckDuckGoSearchRun
import json
import concurrent.futures

def feedback_node(state: AgentState):
    """
    Generates the final report, performs bonus web search for roadmap, 
    and saves the log (including the final turn N).
    """
    print("--- Generating Feedback (Including Bonus Search) ---")
    
    from utils.report import generate_technical_report
    from langchain_openai import ChatOpenAI
    from config import settings
    from agents.manager import ManagerAgent
    
    api_base = settings.OPENAI_API_BASE
    llm = ChatOpenAI(model=settings.MODEL_INTERVIEWER, temperature=0, base_url=api_base)
    
    # 1. Manager Decision
    manager = ManagerAgent(llm)
    manager_decision = manager.evaluate(state)
    manager_report = manager.format_decision_report(manager_decision)
    
    # --- LOGGING FINAL TURN (N) ---
    # According to req: turn N includes Question N, Stop Answer, and Thoughts about final feedback.
    loop_count = state.get("loop_count", 0)
    last_question = state.get("current_question", "")
    messages = state.get("messages", [])
    last_user_message = ""
    if messages and hasattr(messages[-1], "content"):
        last_user_message = messages[-1].content
        
    # Aggregate thoughts for turn N
    turn_thoughts = state.get("current_turn_thoughts", {})
    # Manager's deliberation is part of final thoughts
    turn_thoughts["Manager"] = f"Final evaluation: {manager_decision.get('recommendation', 'N/A')}. Confidence: {manager_decision.get('confidence', 0)}%"
    
    formatted_thoughts = ""
    for agent, thought in turn_thoughts.items():
        formatted_thoughts += f"[{agent}]: {thought}\n"
        
    final_turn_log = {
        "turn_id": loop_count + 1,
        "agent_visible_message": last_question,
        "user_message": last_user_message,
        "internal_thoughts": formatted_thoughts
    }
    
    # 2. Technical Review
    technical_report = generate_technical_report(state, llm)
    
    # 3. Roadmap + Bonus Search (Existing logic)
    internal_thoughts = state.get("internal_thoughts", [])
    gaps = []
    for thought in internal_thoughts:
         if isinstance(thought, dict):
            if thought.get("decision") in ["DECREASE_DIFFICULTY", "MAINTAIN"]:
                gaps.append(thought.get("analysis", ""))

    from duckduckgo_search import DDGS
    links_section = ""
    if gaps:
        print("    üîé Searching for learning resources (Bonus)...")
        top_gaps = gaps[:3] 
        links = []
        def search_gap(gap_text):
            try:
                query = f"guide tutorial documentation {gap_text[:50]}"
                with DDGS() as ddgs:
                    results = list(ddgs.text(query, max_results=1))
                    if results:
                        res = results[0]
                        return f"- **Topic**: {gap_text[:100]}...\n  - **Resource**: [{res['title']}]({res['href']})"
                return None
            except Exception: return None

        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            future_to_gap = {executor.submit(search_gap, gap): gap for gap in top_gaps}
            for future in concurrent.futures.as_completed(future_to_gap):
                result = future.result()
                if result: links.append(result)
        if links:
            links_section = "### üîó –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã (Auto-Generated)\n" + "\n".join(links)

    from utils.report import generate_development_roadmap
    roadmap_core = generate_development_roadmap(state, llm)
    
    full_report = f"""
# üìã –û—Ç—á—ë—Ç –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É –∏–Ω—Ç–µ—Ä–≤—å—é

## üë§ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞–Ω–¥–∏–¥–∞—Ç–µ
- **–ò–º—è**: {state['candidate_info'].get('Name', 'N/A')}
- **–ü–æ–∑–∏—Ü–∏—è**: {state['candidate_info'].get('Position', 'N/A')}
- **–ì—Ä–µ–π–¥**: {state['candidate_info'].get('Grade', 'N/A')}

{manager_report}

{technical_report}

{roadmap_core}

{links_section}

---
*Generated by Multi-Agent Interview Coach with Live Search*
"""

    # Save log with scenario filename
    session_id = state.get("session_id", 1)
    filename = f"interview_log_{session_id}.json"
    
    # Join the accumulated log with the very last turn
    full_log = state.get("interview_log", []) + [final_turn_log]
    
    LoggerUtils.save_log(state['candidate_info'].get('Name', 'N/A'), full_log, full_report, filename=filename)
    
    print("\n" + "="*30)
    print("FINAL FEEDBACK REPORT")
    print("="*30)
    print(full_report)
    
    return {"messages": [AIMessage(content="INTERVIEW_FINISHED")]}
