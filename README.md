# Multi-Agent Interview Coach

Система автоматизации технических интервью на базе LangGraph с многоагентной архитектурой. Проект обеспечивает полный цикл проведения собеседования: от планирования тем до формирования финального экспертного заключения.

## Основные возможности

- **Динамическое планирование**: Генерация персонализированного плана интервью на основе грейда и позиции кандидата.
- **Многоагентная рефлексия**: Разделение ролей анализа (Observer), ведения диалога (Interviewer) и контроля качества (Critic).
- **Self-Correction Loop**: Автоматическая проверка и исправление вопросов интервьюера перед выводом пользователю.
- **Guardrails**: Встроенная фильтрация промпт-инъекций и корректная обработка смены ролей в диалоге.
- **Автоматизированная отчетность**: Генерация детального фидбека с поиском актуальных обучающих материалов через DuckDuckGo Search.

## Технологический стек

- **Core**: Python 3.11
- **Orchestration**: LangGraph, LangChain
- **LLM**: OpenAI GPT models (через LangChain OpenAI)
- **Validation**: Pydantic, Pydantic Settings
- **Frontend**: Streamlit
- **Infrastructure**: Docker, Docker Compose, Makefile

## Структура проекта

```text
interview_coach/
├── agents/                 # Логика специализированных агентов
│   ├── critic.py           # Узел контроля качества вопросов
│   ├── interviewer.py      # Агент ведения диалога
│   ├── manager.py          # Агент принятия финального решения
│   ├── observer.py         # Агент анализа ответов и коррекции сложности
│   └── planner.py          # Агент начального планирования сессии
├── utils/                  # Вспомогательные утилиты
│   ├── llm_utils.py        # Декораторы для ретраев и обработки ошибок LLM
│   ├── logger.py           # Инструментарий для сохранения JSON-логов
│   └── report.py           # Генераторы финального отчета и репозиториев
├── config.py               # Конфигурация приложения и валидация окружения
├── state.py                # Определение схем данных и состояния графа
├── graph.py                # Описание циклического графа и переходов
├── main.py                 # CLI интерфейс приложения
├── streamlit_app.py        # Веб-интерфейс приложения
├── router.py               # Классификатор интентов пользователя (Guardrail)
├── feedback.py             # Узел формирования итогов интервью
├── validate_logs.py        # Скрипт проверки логов на соответствие ТЗ
├── Dockerfile              # Инструкции по сборке контейнера
├── docker-compose.yml      # Оркестрация контейнеров
├── Makefile                # Автоматизация основных команд
└── requirements.txt        # Зависимости проекта
```

## Развертывание и запуск

### 1. Подготовка окружения
Создайте файл `.env` в корневой директории на основе шаблона и укажите ваш API ключ:
```bash
cp .env.example .env
```

### 2. Запуск через Docker (рекомендуется)
Для запуска всех компонентов системы в изолированном окружении:
```bash
docker-compose up --build
```
Интерфейс будет доступен по адресу: `http://localhost:8501`

### 3. Локальный запуск
Для запуска без использования Docker:

**Установка зависимостей:**
```bash
pip install -r requirements.txt
```

**Запуск веб-интерфейса:**
```bash
streamlit run streamlit_app.py
```

**Запуск консольной версии:**
```bash
python main.py
```

## Логирование и проверка

Проект автоматически сохраняет логи каждого интервью в формате `interview_log_{scenario_id}.json`. Для проверки корректности структуры логов используйте встроенную утилиту:
```bash
python validate_logs.py interview_log_1.json
```

## Лицензия
MIT
