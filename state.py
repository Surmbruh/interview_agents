from typing import TypedDict, List, Dict, Annotated, Union, Any, Optional
import operator
from langchain_core.messages import AnyMessage
from pydantic import BaseModel, Field

# === Pydantic Output Schemas (For Structured Outputs) ===

class ObserverOutput(BaseModel):
    """Structured output for Observer Agent."""
    analysis: str = Field(..., description="Analysis of the candidate's answer quality.")
    decision: str = Field(..., description="Decision: INCREASE_DIFFICULTY, DECREASE_DIFFICULTY, MAINTAIN.")
    instruction: str = Field(..., description="Instruction for the Interviewer.")
    topics_covered: Optional[List[str]] = Field(default=[], description="New topics covered in this turn.")
    should_stop: bool = Field(default=False, description="Flag to end the interview.")

class InterviewerOutput(BaseModel):
    """Structured output for Interviewer Agent (used internally, though response is usually text)."""
    response_text: str = Field(..., description="The verification question or response to candidate.")
    topic_status: str = Field(default="ongoing", description="Status of the current topic (e.g., 'completed', 'ongoing').")

class CriticOutput(BaseModel):
    """Structured output for the Quality Critic Agent."""
    status: str = Field(..., description="Decision: APPROVED or REJECTED.")
    feedback: str = Field(default="", description="If REJECTED, specific instructions on what to fix.")

# === Graph State ===

class AgentState(TypedDict):
    """
    State for the Interview Coach graph.
    
    This state is shared between all agents and persisted by MemorySaver.
    Each field serves a specific purpose in the multi-agent workflow.
    """
    
    # === Core Conversation ===
    messages: Annotated[List[AnyMessage], operator.add]
    """Full conversation history between interviewer and candidate."""
    
    # === Candidate Metadata ===
    candidate_info: Dict[str, str]
    """
    Static info about the candidate. Keys:
    - Name: Candidate's name
    - Position: Target position (e.g., "Backend Developer")
    - Grade: Target grade (e.g., "Senior", "Middle")
    - Experience: Years/description of experience
    """

    company_profile: str
    """
    Static description of the company's tech stack and culture.
    Used to ground the Interviewer's questions in reality.
    """
    
    # === Observer's Hidden Thoughts ===
    internal_thoughts: List[Union[str, Dict[str, Any]]]
    """
    List of Observer's analysis for each turn. Each entry is a dict with:
    - analysis: Brief analysis of the response
    - decision: INCREASE_DIFFICULTY / DECREASE_DIFFICULTY / MAINTAIN
    - instruction: What the Interviewer should do next
    - topics_covered: List of topics discussed so far
    - should_stop: Whether to end the interview
    
    This is the "hidden reflection" layer - visible in logs but not to the user.
    """
    
    # === Interview Log for Export ===
    interview_log: Annotated[List[Dict[str, Any]], operator.add]
    """
    Turn-by-turn log for JSON export. Each entry contains:
    - turn_id: Sequential number
    - internal_thoughts: Observer's analysis for this turn
    - user_input: What the candidate said
    - agent_response: What the interviewer responded
    
    Used for generating the final report and audit trail.
    """
    
    # === Control Variables ===
    loop_count: int
    """Number of completed Q&A cycles. Used to limit interview length."""
    
    topics_covered: List[str]
    """
    Running list of topics that have been discussed.
    Used to prevent asking duplicate questions.
    
    Example: ["microservices", "databases", "CI/CD", "testing"]
    """
    
    # === Router State ===
    router_decision: str
    """
    Result of the Guardrail classification:
    - ANSWER: Proceed to Observer -> Interviewer
    - ROLE_REVERSAL: Proceed directly to Interviewer
    - INJECTION: Proceed directly to Interviewer (Refusal)
    - STOP: Proceed to Feedback
    """

    # === Planning State ===
    topic_plan: List[str]
    """
    List of technical topics to be covered, generated by the PlannerAgent.
    Example: ["Python Basics", "GIL", "AsyncIO", "Unit Testing", "SQLAlchemy"]
    """

    # === Quality Loop (Critic) State ===
    critic_feedback: str
    """Feedback from the Quality Critic if the question was REJECTED."""
    
    critic_retry_count: int
    """Number of times the current question has been retried after rejection."""
